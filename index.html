<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Matrix-3D: Omnidirectional Explorable 3D World Generation">
  <meta property="og:title" content="Matrix-3D Project Page"/>
  <meta property="og:description" content="Matrix-3D: Omnidirectional Explorable 3D World Generation"/>
  <meta property="og:url" content="https://arthurhero.github.io/projects/llrm/index.html"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/fig2.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Matrix-3D">
  <meta name="twitter:description" content="Matrix-3D: Omnidirectional Explorable 3D World Generation">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/fig2.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="3D Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Matrix-3D</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body style="margin:0; padding:0;">
  <div style="
    position: fixed;
    top: 0; left: 0; width: 100vw; height: 100vh;
    z-index: -1;

  "></div>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- Logo image -->
            <h1 class="title is-1 publication-title" style="color: #000">Matrix-3D: Omnidirectional Explorable 3D World Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block" style="color: #000"><a href="https://chenziwe.com/" target="_blank">XXX</a><sup>1</sup>,</span>

            </div>
            <div class="is-size-5 publication-authors">
                <span class="eql-cntrb" style="color: #000"><br><sup>1</sup><i>Skywork AI</i></span>
              <!-- <span class="eql-cntrb" style="color: #FFF"><sup>2</sup>Adobe Research</span> -->
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.12781" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/arthurhero/Long-LRM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End paper abstract -->


<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <br>
    <!-- <div class="hero-body is-centered has-text-centered"> -->
      
      <!-- <img src="static/images/logo.jpeg" alt="Matrix-3D Logo" style="width: 200px; height: 125px; vertical-align: middle; margin-bottom: 20px;"> -->
      <!-- <span style="display: inline-block; vertical-align: middle; margin-left: 16px; font-size: 1.3rem; color: #333;">
        Matrix-3D: Omnidirectional Explorable 3D World Generation
      </span> -->
      <!-- <div style="backdrop-filter: blur(12px) saturate(160%) brightness(1.1); background: rgba(255,255,255,0.35); border-radius: 18px; box-shadow: 0 4px 24px rgba(0,0,0,0.08); padding: 24px; display: inline-block;">
        <img src="static/images/overview.png" width="960" height="425" style="border-radius: 12px;">
      </div>
      <br><br>
      <div class="content has-text-justified">
        Given trajectory guidance in the form of scene mesh renderings and corresponding masks—obtained by rendering an estimated mesh along a user-defined camera trajectory—we train an image-to-video diffusion model to generate high-quality panoramic videos that precisely follow the specified trajectory. The generated 2D panoramic content is then lifted into an omnidirectional, explorable 3D world using a large-scale panorama reconstruction model.
      </div> -->
    <!-- </div> -->
      <!-- Viewer区域 -->
      
  </div>
  <h2 class="container is-centered title is-2">Explorable 3D World</h2>
  <div class="container is-centered" id="viewer-container" style="width: 1500px; height: 480px; border-radius: 12px; overflow: hidden;"></div>
  <br>
</section>

<!-- Paper abstract -->
<section class="section hero is-light" style="background-color: #ededed;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <img src="static/images/logo.jpeg" alt="Matrix-3D Logo" style="max-width:120px; margin-bottom: 20px;"> -->

        <h2 class="title is-3">Abstract</h2>
        
        <div class="content has-text-justified">
          <p>
              Explorable 3D world generation from a single image or text prompt forms a cornerstone of spatial intelligence. 
              Recent works utilize video model to achieve wide-scope and generalizable 3D world generation.  However, existing approaches often suffer from limited reconstruction scope and suboptimal visual quality. 
              In this work, we propose <b>Matrix-3D</b>, a framework that utilize panoramic representation for wide-coverage omnidirectional explorable 3D world generation that combines conditional video generation and panoramic 3D reconstruction.
              We first train a trajectory-guided panoramic video diffusion model that employs scene mesh renders as condition, to enable high-quality and geometrically consistent scene video generation.
              To enable 3D world generation, we introduce two methods that lift the 2D content to 3D world, ensuring efficiency and effectiveness.
              To lift the panorama scene video to 3D world, we propose two separate pipelines — a feed-forward large reconstruction model for rapid 3D scene reconstruction and an optimization-based pipeline for accurate and detailed 3D scene reconstruction.
              For efficiency, we introduce a feed-forward panoramic 3D reconstruction model that projects video latents and camera poses to predict omni-directional 3D Gaussian Splatting attributes. To facilitate convergence, we adopt a two-stage training strategy and supervise the model using rendered panoramic novel views. For effectiveness, we also propose a optimization-based reconstruction method.
              However, no existing panoramic video dataset provides associated camera poses. 
              To facilitate effective training, we also introduce the <b>Matrix-Pano</b> dataset — the first large-scale synthetic collection comprising 116,759 high-quality static panoramic video sequences with various annotations.
              Extensive experiments demonstrate the effectiveness of our proposed framework, which achieves state-of-the-art performance in panoramic video generation and 3D world generation.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>
  <img class="container is-centered" src="static/images/bg-method.png" style="max-width:800px; margin-bottom: 20px;">
</section>


<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <br>
    <div class="hero-body is-centered has-text-centered">
      <h2 class="title is-2">Overview of Matrix-3D</h2>
      <!-- <img src="static/images/logo.jpeg" alt="Matrix-3D Logo" style="width: 200px; height: 125px; vertical-align: middle; margin-bottom: 20px;"> -->
      <!-- <span style="display: inline-block; vertical-align: middle; margin-left: 16px; font-size: 1.3rem; color: #333;">
        Matrix-3D: Omnidirectional Explorable 3D World Generation
      </span> -->
      <div style="backdrop-filter: blur(12px) saturate(160%) brightness(1.1); background: rgba(255,255,255,0.35); border-radius: 18px; box-shadow: 0 4px 24px rgba(0,0,0,0.08); padding: 24px; display: inline-block;">
        <img src="static/images/overview.png" width="960" height="425" style="border-radius: 12px;">
      </div>
      <br><br>
      <div class="content has-text-justified">
        Given trajectory guidance in the form of scene mesh renderings and corresponding masks—obtained by rendering an estimated mesh along a user-defined camera trajectory—we train an image-to-video diffusion model to generate high-quality panoramic videos that precisely follow the specified trajectory. The generated 2D panoramic content is then lifted into an omnidirectional, explorable 3D world using a large-scale panorama reconstruction model.
      </div> 
    </div>      
  </div>
  <br>
</section>

<head>
  <meta charset="UTF-8" />
  <title>Butterfly Viewer - SparkControls</title>


  <!-- 模块导入 -->
  <script type="importmap">
  {
    "imports": {
      "three": "https://cdnjs.cloudflare.com/ajax/libs/three.js/0.174.0/three.module.js",
      "@sparkjsdev/spark": "https://sparkjs.dev/releases/spark/0.1.3/spark.module.js"
    }
  }
  </script>
</head>
<body>
  <div id="viewer-container"></div>

  <script type="module">
    import * as THREE from "three";
    import {
      SparkRenderer,
      SplatMesh,
      SparkControls
    } from "@sparkjsdev/spark";

    // 容器与尺寸
    const container = document.getElementById("viewer-container");
    const width = container.clientWidth;
    const height = container.clientHeight;

    // Three.js 基本设置
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(width, height);
    container.appendChild(renderer.domElement);

    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
    camera.position.set(0, 0, 0);
    scene.add(camera);

    // Spark 渲染器
    const spark = new SparkRenderer({ renderer });
    scene.add(spark);
    spark.newViewpoint({ camera, autoUpdate: true });

    // 限定相机范围参数
    const CAMERA_LIMITS = {
      minX: -0.05, maxX: 0.05,
      minY: -0.05, maxY: 0.05,
      minZ: -0.05, maxZ: 0.05
    };

    // 添加 SparkControls（用于键鼠控制）
    const controls = new SparkControls({ canvas: renderer.domElement });
  
    // ✅ 加载蝴蝶模型
    const splat = new SplatMesh({ url: "https://huggingface.co/chenttt/matrix3d/resolve/main/point_cloud.ply" });
    
    splat.scale.y = -1;
    scene.add(splat);
    // 让 splat 模型持续自转
    function animateSplatRotation() {
      if (splat) {
      splat.rotation.y += 0.01;
      }
      requestAnimationFrame(animateSplatRotation);
    }
    animateSplatRotation();
    // 渲染循环
    renderer.setAnimationLoop(() => {
      // 限定相机位置
      camera.position.x = Math.max(CAMERA_LIMITS.minX, Math.min(CAMERA_LIMITS.maxX, camera.position.x));
      camera.position.y = Math.max(CAMERA_LIMITS.minY, Math.min(CAMERA_LIMITS.maxY, camera.position.y));
      camera.position.z = Math.max(CAMERA_LIMITS.minZ, Math.min(CAMERA_LIMITS.maxZ, camera.position.z));

      renderer.render(scene, camera);
      controls.update(camera);
    });

    // 监听窗口缩放
    window.addEventListener("resize", () => {
      const w = container.clientWidth;
      const h = container.clientHeight;
      renderer.setSize(w, h);
      camera.aspect = w / h;
      camera.updateProjectionMatrix();
    });
  </script>
</body>

<!-- End teaser video -->



<section class="section hero is-light" style="background-color: #ededed;">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <img src="static/images/logo.jpeg" alt="Matrix-3D Logo" style="max-width:120px; margin-bottom: 20px;"> -->

      <h2 class="title is-3">Matrix-Pano Dataset: Scalable Synthetic Panoramic Videos</h2>
      <div class="content has-text-justified">
        Existing 3D scene datasets are often limited in scale, inconsistent in quality, and lack accurate camera and geometric annotations. Meanwhile, collecting real-world 3D scene data remains costly. To address these challenges, we introduce the <strong>Matrix-Pano</strong> dataset—a scalable synthetic panoramic video dataset designed for generating high-quality, explorable panoramic sequences.
      </div>

      <!-- Dataset features -->
      <h3 class="title is-4" style="margin-top:2rem;">Dataset Construction & Features</h3>
      <!-- <p>
        <strong>High-Fidelity Simulation & Diverse Environments:</strong><br>
        Matrix-Pano is entirely built in Unreal Engine with highly realistic physics and visual effects. It covers <strong>504 high-quality, large-scale 3D scenes</strong> including both indoor and outdoor environments, supporting diverse weather and lighting conditions. All video sequences are paired with precise camera and trajectory annotations.
      </p> -->
      <!-- Insert image related to dataset here -->
      <img src="static/images/bg.png" alt="Matrix-Pano Dataset Examples" style="margin-top:1rem; max-width:100%;">

      <!-- Trajectory system -->
      <h3 class="title is-4" style="margin-top:2rem;">Automated Trajectory Generation & Capture</h3>
      <!-- <p>
        <strong>Trajectory Generation:</strong><br>
        We propose an efficient sampling algorithm for generating visually coherent camera paths. The system first identifies walkable surfaces using the navigation mesh and constructs a Delaunay triangulation on the 2D plane. Start and end points are randomly selected, and the shortest path is found via Dijkstra’s algorithm. To ensure spatial continuity, paths are smoothed using C²-continuous cubic Hermite interpolation. Only paths longer than 18 meters are retained to guarantee dynamic video sequences.
      </p>
      <p style="margin-top:1rem;">
        <strong>Collision Detection:</strong><br>
        We employ a bounding box proxy method that simplifies objects into 3D bounding volumes based on nearest and farthest points. This allows efficient simulation of motion along trajectories and filters out paths with any geometric intersection or clipping.
      </p>
      <p style="margin-top:1rem;">
        <strong>Camera Control:</strong><br>
        Leveraging a hierarchical adaptive smoothing algorithm combined with PID control, we achieve decoupled damping adjustment in both position and rotation. This design avoids gimbal lock and ensures industrial-grade physically smooth camera movements.
      </p> -->
      <!-- Insert image related to trajectory system here -->
      <img src="static/images/dataset.png" alt="Trajectory and Camera Control" style="margin-top:1rem; max-width:100%;">

      <!-- Scale and open-source plan -->
      <h3 class="title is-4" style="margin-top:2rem;">Scale & Open Source Plan</h3>
      <div class="content has-text-justified">
        Through a rigorous multi-stage generation and filtering process, we retained <strong>116,759 high-quality panoramic video sequences</strong>, each annotated with its corresponding 3D exploration path. A curated subset will be open-sourced to promote research and development in panoramic video generation and 3D scene understanding.
      </div>
    </div>
  </div>
</section>


<!-- Youtube video -->
<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <br>
    <div class="hero-body is-centered has-text-centered">
      <h2 class="title is-2">Result</h2>
      <!-- <img src="static/images/logo.jpeg" alt="Matrix-3D Logo" style="width: 200px; height: 125px; vertical-align: middle; margin-bottom: 20px;"> -->
      <!-- <span style="display: inline-block; vertical-align: middle; margin-left: 16px; font-size: 1.3rem; color: #333;">
        Matrix-3D: Omnidirectional Explorable 3D World Generation
      </span> -->
    </div>      
  </div>
  <br>
</section>

<!-- End youtube video -->

<!--BibTex citation -->

<section class="section hero is-light" style="background-color: #ededed;">

  <div class="container">
    <h2 class="title">BibTeX</h2>
    <div class="columns">
      <!-- <div class="column is-four-fifths"> -->
  
      <pre><code>@article{XXX,
        title={Matrix-3D: Omnidirectional Explorable 3D World Generation},
        author={}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    End of Statcounter Code

  </body>
  </html>
